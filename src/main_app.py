# src/main_app.py
import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
import uuid
from src.core.graph_builder import graph
from src.features.profile_management.resolver import resolve_store_id_from_name
from src.services.profile_service import profile_manager

st.set_page_config(page_title="ì†Œìƒê³µì¸ AI ë¹„ë°€ìƒë‹´ì‚¬ ğŸ¤–", layout="wide")
st.title("ğŸª ì†Œìƒê³µì¸ AI ë¹„ë°€ìƒë‹´ì‚¬")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())
if "current_profile" not in st.session_state:
    st.session_state.current_profile = None
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 1. ì„¸ì…˜ ì‹œì‘: í”„ë¡œí•„ ë¡œë“œ ---
if not st.session_state.current_profile:
    st.info("ìƒë‹´ì„ ìœ„í•´ ë¨¼ì € ê°€ë§¹ì  ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ìƒí˜¸ëª…ì€ `{ìƒí˜¸ëª…***}` í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    store_name_query = st.text_input("ë¶„ì„í•  ê°€ë§¹ì ëª…ì„ ì…ë ¥í•˜ì„¸ìš”.", placeholder="ì˜ˆ: ì„±ë™êµ¬ {ê³ í–¥***}")

    if st.button("ìƒë‹´ ì‹œì‘"):
        if store_name_query:
            with st.spinner(f"'{store_name_query}' ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘..."):
                store_id = resolve_store_id_from_name(store_name_query)
                if store_id:
                    profile = profile_manager.get_profile(store_id)
                    if "error" not in profile:
                        st.session_state.current_profile = profile
                        st.session_state.messages = [
                            AIMessage(content=f"ì•ˆë…•í•˜ì„¸ìš”! '{profile['core_data']['basic_info']['store_name_masked']}' ì‚¬ì¥ë‹˜. ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
                        ]
                        st.rerun()
                    else:
                        st.error(f"í”„ë¡œí•„ ë¡œë”© ì‹¤íŒ¨: {profile['error']}")
                else:
                    st.error("í•´ë‹¹í•˜ëŠ” ê°€ë§¹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒí˜¸ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            st.warning("ê°€ë§¹ì ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
else:
    # --- 2. ëŒ€í™” ì§„í–‰ ---
    profile_name = st.session_state.current_profile['core_data']['basic_info']['store_name_masked']
    st.success(f"í˜„ì¬ '{profile_name}' ê°€ë§¹ì ì— ëŒ€í•´ ìƒë‹´ ì¤‘ì…ë‹ˆë‹¤.")

    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for msg in st.session_state.messages:
        with st.chat_message(msg.type):
            st.markdown(msg.content)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append(HumanMessage(content=prompt))
        with st.chat_message("human"):
            st.markdown(prompt)

        with st.chat_message("ai"):
            with st.status("AIê°€ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...", expanded=True) as status:
                inputs = {
                    "messages": [HumanMessage(content=prompt)],
                    "current_profile": st.session_state.current_profile
                }
                config = {"configurable": {"thread_id": st.session_state.thread_id}}
                
                # ìµœì¢… ìƒíƒœë¥¼ ì €ì¥í•  ë³€ìˆ˜
                final_state = None 
                
                for chunk in graph.stream(inputs, config=config):
                    # ê° ë…¸ë“œì˜ ì¶œë ¥ì„ í™•ì¸í•˜ê³  UI ì—…ë°ì´íŠ¸
                    if "router" in chunk:
                        status.update(label="ì˜ë„ë¥¼ íŒŒì•…í•˜ê³  ìµœì ì˜ ì „ë¬¸ê°€ë¥¼ ì°¾ëŠ” ì¤‘...")
                    
                    if "planner" in chunk and chunk["planner"].get("plan"):
                        plan_steps = "\n".join(f"â³ {step}" for step in chunk["planner"]["plan"])
                        status.update(label=f"ì‘ì—… ê³„íš ìˆ˜ë¦½ ì™„ë£Œ!\n{plan_steps}")

                    if "executor" in chunk and chunk["executor"].get("past_steps"):
                        past_steps_str = "\n".join(f"âœ… {step[0]}" for step in chunk["executor"]["past_steps"])
                        remaining_plan_str = "\n".join(f"â³ {step}" for step in chunk["executor"]["plan"])
                        status.update(label=f"ì‘ì—… ìˆ˜í–‰ ì¤‘...\n{past_steps_str}\n{remaining_plan_str}")

                    if "synthesizer" in chunk:
                        status.update(label="ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„± ì¤‘...")
                        final_response = chunk["synthesizer"]["messages"][-1].content

                    final_state = chunk
                
                status.update(label="ë‹µë³€ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", state="complete")
            
            # --- ìµœì¢… ë‹µë³€ ì¶”ì¶œ ë¡œì§ ---
            final_response = ""
            if final_state:
                last_node_key = list(final_state.keys())[0]
                messages = final_state[last_node_key].get("messages")
                if messages:
                    final_response = messages[-1].content

            st.markdown(final_response)

        if final_response:
            st.session_state.messages.append(AIMessage(content=final_response))