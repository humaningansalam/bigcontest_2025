# src/core/graph_builder.py

import json
import os
from typing import Dict, Any

import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import AIMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph

from src.config import PRIMARY_MODEL_NAME
from src.core.intent_classifier import classify_intent
from src.core.state import AgentState
from src.core.tool_registry import tool_registry
from src.utils.errors import create_tool_error
from .planner_prompt import build_planner_prompt

# --- 1. ì „ì—­ ì„¤ì • ë° LLM ì´ˆê¸°í™” ---
load_dotenv()
google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))

# í”„ë¡œì íŠ¸ì˜ í•µì‹¬ LLMì„ ì •ì˜
llm = ChatGoogleGenerativeAI(model=PRIMARY_MODEL_NAME, google_api_key=google_api_key, temperature=0)

# ë“±ë¡ëœ ëª¨ë“  ë„êµ¬ì˜ ì„¤ëª… ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê³  Plannerê°€ ê³„íš ìˆ˜ë¦½ ì‹œ ì°¸ê³ 
TOOL_DESCRIPTIONS = tool_registry.get_all_descriptions()

# --- 2. ê·¸ë˜í”„ ë…¸ë“œ(Graph Nodes) ì •ì˜ ---

def simple_responder_node(state: AgentState) -> dict:
    """'greeting', 'unknown' ë“± ê°„ë‹¨í•œ ì˜ë„ì— ëŒ€í•´ ì¦‰ì‹œ ë‹µë³€í•˜ëŠ” ê²½ëŸ‰ ë…¸ë“œì…ë‹ˆë‹¤."""
    print("--- ğŸ‘‹ Simple Responder í™œë™ ì‹œì‘ ---")
    user_query = state['messages'][-1].content
    intent = classify_intent(user_query)

    if intent == 'greeting':
        response_content = "ì•ˆë…•í•˜ì„¸ìš”, ì‚¬ì¥ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    else:
        response_content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ëª…í™•í•˜ê²Œ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ìš°ë¦¬ ê°€ê²Œ ì¬ë°©ë¬¸ìœ¨ ë¶„ì„í•´ì¤˜'ì™€ ê°™ì´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?"

    return {
        "messages": [AIMessage(content=response_content)],
        "final_output": response_content
    }


def router_node(state: AgentState) -> dict:
    """ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ì ì ˆí•œ ë‹¤ìŒ ë…¸ë“œë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤."""
    print("--- ğŸš¦ Router í™œë™ ì‹œì‘ ---")
    user_query = state['messages'][-1].content
    intent = classify_intent(user_query)
    print(f"--- ë¶„ì„ëœ ì˜ë„: {intent} ---")

    # ì‹œë‚˜ë¦¬ì˜¤ 1: ë³µì¡í•œ ë¶„ì„ì´ í•„ìš”í•˜ì—¬ Plannerì—ê²Œ ê³„íš ìˆ˜ë¦½ì„ ìš”ì²­
    if intent in ["data_analysis", "marketing_idea", "general_rag_search"]:
        print("--- [Router] Planner í˜¸ì¶œ ê²°ì • ---")
        allowed_tools = ["rag_searcher"] if intent == "general_rag_search" else None
        return {"next_node": "planner", "allowed_tools": allowed_tools}

    # ì‹œë‚˜ë¦¬ì˜¤ 2: ë‹¨ì¼ ë„êµ¬ë¡œ í•´ê²° ê°€ëŠ¥í•˜ì—¬ Plannerë¥¼ ê±´ë„ˆë›°ê³  ë°”ë¡œ Executor í˜¸ì¶œ
    elif intent in ["bigcon_request", "video_recommendation", "policy_recommendation"]:
        print(f"--- [Router] ë‹¨ì¼ ë„êµ¬({intent}) ì§ì ‘ í˜¸ì¶œ ê²°ì • ---")
        tool_map = {
            "bigcon_request": "action_card_generator",
            "video_recommendation": "video_recommender",
            "policy_recommendation": "policy_recommender"
        }
        tool_name = tool_map[intent]
        plan = [{
            "tool_name": tool_name,
            "tool_input": {"user_query": user_query},
            "thought": f"ì‚¬ìš©ì ì˜ë„ '{intent}'ì— ë”°ë¼ {tool_name} ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤."
        }]
        return {"next_node": "executor", "plan": plan, "past_steps": []}

    # ì‹œë‚˜ë¦¬ì˜¤ 3: ë„êµ¬ ì‚¬ìš© ì—†ì´ í”„ë¡œí•„ ì •ë³´ë§Œìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥
    elif intent == "profile_query":
        print("--- [Router] Synthesizer ì§ì ‘ í˜¸ì¶œ ê²°ì • (í”„ë¡œí•„ ê¸°ë°˜ ë‹µë³€) ---")
        return {"next_node": "synthesizer", "plan": []}

    # ì‹œë‚˜ë¦¬ì˜¤ 4: ì¸ì‚¬ ë“± ê°„ë‹¨í•œ ì‘ë‹µ
    else:
        print("--- [Router] Simple Responder í˜¸ì¶œ ê²°ì • ---")
        return {"next_node": "simple_responder"}


def planner_node(state: AgentState) -> dict:
    """ì‚¬ìš©ì ìš”ì²­ê³¼ í˜„ì¬ ìƒíƒœë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤."""
    print("--- ğŸ¤” Planner í™œë™ ì‹œì‘ ---")
    allowed_list = state.get("allowed_tools")
    effective_tools = {key: TOOL_DESCRIPTIONS[key] for key in allowed_list if key in TOOL_DESCRIPTIONS} if allowed_list else TOOL_DESCRIPTIONS
    effective_tool_descriptions_str = "\n".join([f"- `{name}`: {desc}" for name, desc in effective_tools.items()])

    prompt = build_planner_prompt(state, effective_tool_descriptions_str)
    planner_chain = llm | JsonOutputParser()
    plan_json = planner_chain.invoke(prompt)

    print(f"--- ğŸ“ ìˆ˜ë¦½ëœ ê³„íš ---\n" + json.dumps(plan_json, indent=2, ensure_ascii=False))
    return {"plan": plan_json, "past_steps": []}


def executor_node(state: AgentState) -> dict:
    """ê³„íš(plan)ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ìƒíƒœ(state)ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    print("--- âš™ï¸ Executor í™œë™ ì‹œì‘ ---")
    plan = state.get("plan", [])
    if not plan:
        return {}

    step = plan[0]
    tool_name = step.get("tool_name")
    invoke_args = step.get("tool_input", {}).copy()

    print(f"--- [ì‹¤í–‰] ë„êµ¬: {tool_name} // ì¸ì: {invoke_args} ---")
    print(f"--- [ì‚¬ê³  ê³¼ì •] {step.get('thought', 'N/A')} ---")

    try:
        tool = tool_registry.get_tool(tool_name)

        # ë„êµ¬ê°€ í•„ìš”ë¡œ í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸(profile, user_query ë“±)ë¥¼ ë™ì ìœ¼ë¡œ ì£¼ì…
        tool_meta = tool_registry.get_tool_metadata(tool_name)
        current_profile = state.get("current_profile")
        if tool_meta.get("needs_profile") and current_profile:
            invoke_args["profile"] = current_profile
        if tool_meta.get("needs_user_query"):
            invoke_args["user_query"] = state["messages"][-1].content
        if tool_meta.get("needs_store_id") and current_profile:
            invoke_args["store_id"] = current_profile.get("profile_id")

        tool_output_dict = tool.invoke(invoke_args)
        tool_output = ToolOutput.model_validate(tool_output_dict)

        past_steps = state.get("past_steps", []) + [(json.dumps(step, ensure_ascii=False), tool_output.content)]
        sources = state.get("sources", []) + tool_output.sources
        updated_state = {"past_steps": past_steps, "sources": sources}

        # ë„êµ¬ê°€ 'ìµœì¢… ë‹µë³€'ì„ ìƒì„±í–ˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸
        if tool_output.is_final_answer:
            updated_state.update({
                "is_final_answer": True,
                "final_output": tool_output.content,
                "messages": state["messages"] + [AIMessage(content=tool_output.content)],
                "plan": []  # ê³„íš ì¢…ë£Œ
            })
        else:
            updated_state["plan"] = plan[1:]  # ë‹¤ìŒ ê³„íšìœ¼ë¡œ ì´ë™

        return updated_state

    except Exception as e:
        print(f"--- ğŸš¨ EXECUTOR ì˜ˆì™¸ ë°œìƒ: {e} ---")
        error_message = create_tool_error(tool_name, e)
        past_steps = state.get("past_steps", []) + [(json.dumps(step, ensure_ascii=False), error_message)]
        return {"plan": plan[1:], "past_steps": past_steps}


def synthesizer_node(state: AgentState) -> dict:
    """ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´(past_steps)ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("--- âœï¸ Synthesizer ìµœì¢… ë‹µë³€ ì‘ì„± ---")
    user_query = state['messages'][-1].content
    conversation_history = "\n".join([f"- {msg.type}: {msg.content}" for msg in state.get('messages', [])[:-1]])
    profile_json_str = json.dumps(state.get('current_profile'), ensure_ascii=False, indent=2)

    if state.get("past_steps"):
        evidence = "\n\n".join([f"**ì‹¤í–‰ ë‚´ìš©:** {step}\n**ê²°ê³¼:**\n{str(result)[:1000]}..." for step, result in state.get("past_steps")])
        base_context = f"**[ìˆ˜ì§‘ëœ ê·¼ê±° ìë£Œ]**\n{evidence}\n\n**[ì°¸ê³ : ê°€ë§¹ì  í”„ë¡œí•„]**\n{profile_json_str}"
    else:
        base_context = f"**[ê°€ë§¹ì  í”„ë¡œí•„ ì •ë³´]**\n{profile_json_str}"

    prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ [ì‚¬ìš©ì ì§ˆë¬¸]ì— ëŒ€í•´, ì£¼ì–´ì§„ [í•µì‹¬ ê·¼ê±°]ì™€ [ì´ì „ ëŒ€í™” ë‚´ìš©]ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë§Œì•½ [í•µì‹¬ ê·¼ê±°]ì— [ì¶œì²˜]ë‚˜ [ì°¸ê³  ìë£Œ]ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, í•´ë‹¹ ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ë‹µë³€ì˜ ì‹ ë¢°ë„ë¥¼ ë†’ì—¬ì£¼ì„¸ìš”.

**[ì´ì „ ëŒ€í™” ë‚´ìš©]**
{conversation_history}

**[ì‚¬ìš©ì ì§ˆë¬¸]**
{user_query}

**[í•µì‹¬ ê·¼ê±°]**
{base_context}

**[ìµœì¢… ë‹µë³€]**
"""
    response = llm.invoke(prompt)
    return {
        "messages": [AIMessage(content=response.content)],
        "final_output": response.content
    }


def after_executor_logic(state: AgentState) -> str:
    """Executor ë…¸ë“œ ì‹¤í–‰ í›„, ë‹¤ìŒìœ¼ë¡œ ì´ë™í•  ê²½ë¡œë¥¼ ê²°ì •í•˜ëŠ” ì¡°ê±´ë¶€ ë¡œì§"""
    if state.get("is_final_answer"):
        # ë„êµ¬ê°€ ìµœì¢… ë‹µë³€ì„ ìƒì„±í–ˆìœ¼ë¯€ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¦‰ì‹œ ì¢…ë£Œ
        return "end"
    elif state.get("plan"):
        # ì•„ì§ ì‹¤í–‰í•  ê³„íšì´ ë‚¨ì•„ìˆìœ¼ë¯€ë¡œ Executorë¥¼ ë‹¤ì‹œ ì‹¤í–‰
        return "continue"
    else:
        # ëª¨ë“  ê³„íšì´ ëë‚¬ìœ¼ë¯€ë¡œ, ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±
        return "synthesize"


# --- 3. ê·¸ë˜í”„(Graph) êµ¬ì„± ë° ì»´íŒŒì¼ ---

workflow = StateGraph(AgentState)

# ê·¸ë˜í”„ì— ê° ë…¸ë“œë¥¼ ì¶”ê°€
workflow.add_node("router", router_node)
workflow.add_node("planner", planner_node)
workflow.add_node("executor", executor_node)
workflow.add_node("synthesizer", synthesizer_node)
workflow.add_node("simple_responder", simple_responder_node)

# ì›Œí¬í”Œë¡œìš°ì˜ ì‹œì‘ì ì„ 'router'ë¡œ ì„¤ì •
workflow.set_entry_point("router")

# ë…¸ë“œ ê°„ì˜ ì—°ê²°(ì—£ì§€)ì„ ì •ì˜
workflow.add_conditional_edges(
    "router",
    lambda state: state.get("next_node"),
    {
        "planner": "planner",
        "executor": "executor",
        "synthesizer": "synthesizer",
        "simple_responder": "simple_responder"
    }
)
workflow.add_edge("planner", "executor")
workflow.add_conditional_edges(
    "executor",
    after_executor_logic,
    {
        "continue": "executor",      # ê³„ì† ì‹¤í–‰
        "synthesize": "synthesizer",  # ì¢…í•©
        "end": END                   # ì¢…ë£Œ
    }
)
workflow.add_edge("synthesizer", END)
workflow.add_edge("simple_responder", END) # simple_responderëŠ” í•­ìƒ ë§ˆì§€ë§‰

# ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë©”ëª¨ë¦¬ ì„¸ì´ë²„ë¥¼ ì„¤ì •
memory = MemorySaver()

# ìµœì¢…ì ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ë¥¼ ìƒì„±
graph = workflow.compile(checkpointer=memory)